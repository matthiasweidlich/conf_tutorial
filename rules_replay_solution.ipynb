{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rules_replay_solution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthiasweidlich/conf_tutorial/blob/master/rules_replay_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dGNrw7MDhwr",
        "colab_type": "text"
      },
      "source": [
        "# Hands-On Exercise 2: Rule Checking and Replay-based Conformance\n",
        "\n",
        "In this exercise, you will take up the real-life event log of a Dutch financial institute, known already from the earlier notebook. Be reminded that you should be able to clone the repository containing the notebooks and the example data with the code in the next cell. If this does not work, however, you can also download the event log (XES format, please unzip) [here](http://www.win.tue.nl/bpi/doku.php?id=2012:challenge) and then either copy it to your google drive, mount it, and read it from there, or directly upload it using your browser.\n",
        "\n",
        "Also, further details can be found in the [description of the dataset](http://www.win.tue.nl/bpi/doku.php?id=2012:challenge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76CKPHMlDhw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "82073d98-2ba4-4610-b057-4e9f0a99d380"
      },
      "source": [
        "# basic configuration\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# import data from google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# direct data upload\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "# clone the repository that contains the notebooks and also the data file\n",
        "! git clone https://github.com/matthiasweidlich/conf_tutorial.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'conf_tutorial'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 40 (delta 16), reused 13 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAP26A4kDhxN",
        "colab_type": "text"
      },
      "source": [
        "## Import Event Log\n",
        "The following method imports the log file and returns it in a list structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgalrSbIDhxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as et\n",
        "\n",
        "def load_xes(file, event_filter = []):\n",
        "    log = []\n",
        "    \n",
        "    tree = et.parse(file)\n",
        "    data = tree.getroot()\n",
        "    \n",
        "    # find all traces\n",
        "    traces = data.findall('{http://www.xes-standard.org/}trace')\n",
        "    \n",
        "    for t in traces:\n",
        "        trace_id = None\n",
        "        \n",
        "        # get trace id\n",
        "        for a in t.findall('{http://www.xes-standard.org/}string'):\n",
        "            if a.attrib['key'] == 'concept:name':\n",
        "                trace_id = a.attrib['value']\n",
        "        \n",
        "        events = []\n",
        "        # events\n",
        "        for event in t.iter('{http://www.xes-standard.org/}event'):\n",
        "            \n",
        "            e = {'name': None, 'timestamp': None, 'resource': None, 'transition': None}\n",
        "            \n",
        "            for a in event:\n",
        "                e[a.attrib['key'].split(':')[1]] = a.attrib['value']\n",
        "            \n",
        "            if e['name'] in event_filter or len(event_filter) == 0:\n",
        "                events.append(e)\n",
        "        \n",
        "        # add trace to log\n",
        "        if len(events) > 0:\n",
        "            log.append({'trace_id': trace_id, 'events': events})\n",
        "        \n",
        "    return log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWx5L0-QDhxj",
        "colab_type": "text"
      },
      "source": [
        "Now import the given log and compute the trace variants of the log along with their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgiU7VsnDhxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "0da76b68-d108-477a-d439-abb1e4c1e5fc"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "log_file = 'conf_tutorial/financial_log.xes'\n",
        "log = load_xes(log_file)\n",
        "\n",
        "print('Load log with %s traces.' %len(log))\n",
        "\n",
        "trace_variants = {}\n",
        "for trace in log:\n",
        "    events = []\n",
        "    for event in trace['events']:\n",
        "        events.append(event['name'])\n",
        "    trace_variants[tuple(events)] = trace_variants.get(tuple(events), 0) + 1\n",
        "    \n",
        "# print the two most frequent variants\n",
        "trace_variants_sorted_by_freq = sorted(trace_variants.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pprint(trace_variants_sorted_by_freq[:2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load log with 13087 traces.\n",
            "[(('A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_DECLINED'), 3429),\n",
            " (('A_SUBMITTED',\n",
            "   'A_PARTLYSUBMITTED',\n",
            "   'W_Afhandelen leads',\n",
            "   'W_Afhandelen leads',\n",
            "   'A_DECLINED',\n",
            "   'W_Afhandelen leads'),\n",
            "  1872)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XlqD30dDhx6",
        "colab_type": "text"
      },
      "source": [
        "## Import Process Model\n",
        "\n",
        "For the log, we process model is given that is specificed as a Petri net. Such a process model is typically created manually. For this particular example, however, the model has been discovered automatically using the Inductive Miner, applying some noise filtering threshold. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_09nxDhHDhx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "e0e70d6e-8028-4028-f789-f9d2a8a4d306"
      },
      "source": [
        "%run ./conf_tutorial/pn.py\n",
        "\n",
        "net = PetriNet()\n",
        "load(net, \"bpi12_80_noise.pnml\")\n",
        "\n",
        "# mark the initial place\n",
        "net.add_marking(1,1)\n",
        "# visualise it \n",
        "draw_petri_net(net)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cf517af947df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPetriNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bpi12_80_noise.pnml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# mark the initial place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/conf_tutorial/pn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(input_net, filename)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mplace_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxmltree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{http://www.pnml.org/version-2009/grammar/pnml}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m   1195\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bpi12_80_noise.pnml'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ3HT9SxDhyS",
        "colab_type": "text"
      },
      "source": [
        "Set up some helper dictionaries to relate IDs and labels to each other. Observe that activity labels are only assigned to single transitions. However, multiple transitions may carry a _tau_ label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh3g0yFYDhyW",
        "colab_type": "code",
        "colab": {},
        "outputId": "b1d62ea9-ecfd-4726-de30-2f90870479fb"
      },
      "source": [
        "# helper mappings between ids and labels\n",
        "mapping = net.get_mapping()\n",
        "rev_mapping = {}\n",
        "for k, v in net.get_mapping().items():\n",
        "    for k2 in v:\n",
        "        rev_mapping[k2] = k\n",
        "\n",
        "from pprint import pprint\n",
        "# mapping from labels to LISTS of transitions ids\n",
        "pprint(mapping)\n",
        "\n",
        "# mapping from transitions id to label\n",
        "pprint(rev_mapping)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A_ACTIVATED': [-37],\n",
            " 'A_APPROVED': [-36],\n",
            " 'A_CANCELLED': [-13],\n",
            " 'A_DECLINED': [-24],\n",
            " 'A_FINALIZED': [-12],\n",
            " 'A_PARTLYSUBMITTED': [-2],\n",
            " 'A_PREACCEPTED': [-3],\n",
            " 'A_REGISTERED': [-35],\n",
            " 'A_SUBMITTED': [-1],\n",
            " 'O_ACCEPTED': [-32],\n",
            " 'O_CANCELLED': [-15],\n",
            " 'O_CREATED': [-17],\n",
            " 'O_DECLINED': [-23],\n",
            " 'O_SELECTED': [-11],\n",
            " 'O_SENT': [-18],\n",
            " 'O_SENT_BACK': [-26],\n",
            " 'W_Afhandelen leads': [-6],\n",
            " 'W_Beoordelen fraude': [-5],\n",
            " 'W_Completeren aanvraag': [-7],\n",
            " 'W_Nabellen incomplete dossiers': [-31],\n",
            " 'W_Nabellen offertes': [-19],\n",
            " 'W_Valideren aanvraag': [-30],\n",
            " 'W_Wijzigen contractgegevens': [-38],\n",
            " 'tau': [-4,\n",
            "         -8,\n",
            "         -9,\n",
            "         -10,\n",
            "         -14,\n",
            "         -16,\n",
            "         -20,\n",
            "         -21,\n",
            "         -22,\n",
            "         -25,\n",
            "         -27,\n",
            "         -28,\n",
            "         -29,\n",
            "         -33,\n",
            "         -34,\n",
            "         -39,\n",
            "         -40,\n",
            "         -41,\n",
            "         -42]}\n",
            "{-42: 'tau',\n",
            " -41: 'tau',\n",
            " -40: 'tau',\n",
            " -39: 'tau',\n",
            " -38: 'W_Wijzigen contractgegevens',\n",
            " -37: 'A_ACTIVATED',\n",
            " -36: 'A_APPROVED',\n",
            " -35: 'A_REGISTERED',\n",
            " -34: 'tau',\n",
            " -33: 'tau',\n",
            " -32: 'O_ACCEPTED',\n",
            " -31: 'W_Nabellen incomplete dossiers',\n",
            " -30: 'W_Valideren aanvraag',\n",
            " -29: 'tau',\n",
            " -28: 'tau',\n",
            " -27: 'tau',\n",
            " -26: 'O_SENT_BACK',\n",
            " -25: 'tau',\n",
            " -24: 'A_DECLINED',\n",
            " -23: 'O_DECLINED',\n",
            " -22: 'tau',\n",
            " -21: 'tau',\n",
            " -20: 'tau',\n",
            " -19: 'W_Nabellen offertes',\n",
            " -18: 'O_SENT',\n",
            " -17: 'O_CREATED',\n",
            " -16: 'tau',\n",
            " -15: 'O_CANCELLED',\n",
            " -14: 'tau',\n",
            " -13: 'A_CANCELLED',\n",
            " -12: 'A_FINALIZED',\n",
            " -11: 'O_SELECTED',\n",
            " -10: 'tau',\n",
            " -9: 'tau',\n",
            " -8: 'tau',\n",
            " -7: 'W_Completeren aanvraag',\n",
            " -6: 'W_Afhandelen leads',\n",
            " -5: 'W_Beoordelen fraude',\n",
            " -4: 'tau',\n",
            " -3: 'A_PREACCEPTED',\n",
            " -2: 'A_PARTLYSUBMITTED',\n",
            " -1: 'A_SUBMITTED'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMRGzd_-Dhyn",
        "colab_type": "text"
      },
      "source": [
        "Next, we illustrate how the currently enabled transitions may be identified, how the marking is changed by firing a transition, and how the marking may be adapted to enable a transition. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myJEDGtHDhyt",
        "colab_type": "code",
        "colab": {},
        "outputId": "bffb3a93-e7d8-40e9-897a-89ebc9568fb2"
      },
      "source": [
        "print(\"Initial marking: \", net.get_marking())\n",
        "\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions in initial marking: \", list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "# Fire enabled transition (take the first, but there is only one)\n",
        "net.fire_transition(enabled[0])\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions after firing first transition: \", list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "\n",
        "# Check whether the transition with label 'O_CREATED' is enabled (there is only one transition carrying this label)\n",
        "print(\"Is transition 'O_CREATED' enabled?\", net.is_enabled(net.get_mapping()['O_CREATED'][0]))\n",
        "\n",
        "# Enable the transition by changing the marking and adding tokens to the input places\n",
        "input_places = net.get_input_places(net.get_mapping()['O_CREATED'][0])\n",
        "\n",
        "for p in input_places:\n",
        "    net.add_marking(p,1)\n",
        "\n",
        "# Check whether the transition with label 'O_CREATED' is enabled (there is only one transition carrying this label)\n",
        "print(\"Is transition 'O_CREATED' enabled after tokens have been added?\", net.is_enabled(net.get_mapping()['O_CREATED'][0]))\n",
        "\n",
        "# Check whether further transitions have been enabled by adding the token to the place in the preset of the respective transition\n",
        "net.fire_transition(enabled[0])\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions after adapting the marking: \", list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "\n",
        "print(\"Current marking: \", net.get_marking())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial marking:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Enabled transitions in initial marking:  ['A_SUBMITTED']\n",
            "Enabled transitions after firing first transition:  ['A_PARTLYSUBMITTED']\n",
            "Is transition 'O_CREATED' enabled? False\n",
            "Is transition 'O_CREATED' enabled after tokens have been added? True\n",
            "Enabled transitions after adapting the marking:  ['A_PREACCEPTED', 'tau', 'O_CREATED']\n",
            "Current marking:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkoNygqDhy7",
        "colab_type": "text"
      },
      "source": [
        "## Task: Implement a Replay-based Fitness Measure\n",
        "\n",
        "This function shall take a Petri net and a log that is represented as a dictionary (mapping a trace variant to the count of the trace variant)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDUEupg-Dhy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def replay_trace(net: PetriNet, trace: []) -> (int, int, int, int):\n",
        "    produced = 1\n",
        "    consumed = 1\n",
        "    missing = 0\n",
        "\n",
        "    # replay trace, event by event\n",
        "    for event in trace:\n",
        "        # identify transition, assumption here is that there is only one transition for the label\n",
        "        transition = net.get_mapping()[event][0]\n",
        "        # check if the transition is enabled\n",
        "        if not net.is_enabled(transition):\n",
        "            # not enabled, so add a token to all input places that are not marked\n",
        "            for p in net.get_input_places(transition):\n",
        "                if net.marking[net.index_of_place(p)] == 0:\n",
        "                    # record the token as missing\n",
        "                    missing += 1\n",
        "                    net.add_marking(p, 1)\n",
        "\n",
        "        # record the numbers produced and consumed tokens when firing the transition\n",
        "        produced += len(net.get_input_places(transition))\n",
        "        consumed += len(net.get_output_places(transition))\n",
        "        net.fire_transition(transition)\n",
        "\n",
        "    # we expect one token left, everything else counts as remaining\n",
        "    remaining = sum(net.get_marking()) - 1\n",
        "    return produced, consumed, missing, remaining\n",
        "\n",
        "\n",
        "def fitness(net: PetriNet, log_freq: dict) -> float:\n",
        "    sum_prod = 0\n",
        "    sum_cons = 0\n",
        "    sum_miss = 0\n",
        "    sum_rema = 0\n",
        "\n",
        "    for trace_var, freq in log_freq.items():\n",
        "        # keep copy of marking\n",
        "        marking = list(net.get_marking())\n",
        "        # replay trace\n",
        "        replay_values = replay_trace(net, trace_var)\n",
        "        sum_prod += log_freq[trace_var] * replay_values[0]\n",
        "        sum_cons += log_freq[trace_var] * replay_values[1]\n",
        "        sum_miss += log_freq[trace_var] * replay_values[2]\n",
        "        sum_rema += log_freq[trace_var] * replay_values[3]\n",
        "        # restore marking\n",
        "        for k,v in net.places.items():\n",
        "            net.add_marking(v, marking[k])\n",
        "\n",
        "    return 0.5 * (1 - sum_miss / sum_cons) + 0.5 * (1 - sum_rema / sum_prod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNe3rwXxDhzI",
        "colab_type": "text"
      },
      "source": [
        "Measure fitness of the most frequent trace variant: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saN_S2ZnDhzK",
        "colab_type": "code",
        "colab": {},
        "outputId": "60bc3e5c-d569-446e-f141-2f93276af73d"
      },
      "source": [
        "log_1 = {t[0]:t[1] for t in trace_variants_sorted_by_freq[0:1]}\n",
        "fitness_value = fitness(net, log_1)\n",
        "print(\"Fitness value of most frequent trace variant:\", fitness_value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_DECLINED') 3429\n",
            "{('A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_DECLINED'): 3429}\n",
            "Fitness value of most frequent trace variant: 0.375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvEh62rADhzX",
        "colab_type": "text"
      },
      "source": [
        "Now, see how the fitness value changes when considering the _k_-most frequent trace variants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntNc8c4HDhza",
        "colab_type": "code",
        "colab": {},
        "outputId": "6041c057-a7d6-4c33-851a-53a8d59e8157"
      },
      "source": [
        "fitness_value = 0\n",
        "for k in range(30):\n",
        "    log_k = {t[0]:t[1] for t in trace_variants_sorted_by_freq[k:k+1]}\n",
        "    log_x = {t[0]:t[1] for t in trace_variants_sorted_by_freq[0:k+1]}\n",
        "    fitness_value_k = fitness(net, log_k)\n",
        "    fitness_value = fitness(net, log_x)\n",
        "    print(\"Fitness value of the single %s-most frequent trace variant: %f\" % (k+1, fitness_value))\n",
        "    print(\"Fitness value of %s-most frequent trace variants: %f\" % (k+1, fitness_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitness value of 1-most frequent trace variants: 0.375000\n",
            "Fitness value of 2-most frequent trace variants: 0.296477\n",
            "Fitness value of 3-most frequent trace variants: 0.285656\n",
            "Fitness value of 4-most frequent trace variants: 0.301271\n",
            "Fitness value of 5-most frequent trace variants: 0.301708\n",
            "Fitness value of 6-most frequent trace variants: 0.306001\n",
            "Fitness value of 7-most frequent trace variants: 0.311396\n",
            "Fitness value of 8-most frequent trace variants: 0.309831\n",
            "Fitness value of 9-most frequent trace variants: 0.310766\n",
            "Fitness value of 10-most frequent trace variants: 0.312380\n",
            "Fitness value of 11-most frequent trace variants: 0.311980\n",
            "Fitness value of 12-most frequent trace variants: 0.309169\n",
            "Fitness value of 13-most frequent trace variants: 0.313382\n",
            "Fitness value of 14-most frequent trace variants: 0.313607\n",
            "Fitness value of 15-most frequent trace variants: 0.312281\n",
            "Fitness value of 16-most frequent trace variants: 0.311480\n",
            "Fitness value of 17-most frequent trace variants: 0.310049\n",
            "Fitness value of 18-most frequent trace variants: 0.309093\n",
            "Fitness value of 19-most frequent trace variants: 0.310146\n",
            "Fitness value of 20-most frequent trace variants: 0.311829\n",
            "Fitness value of 21-most frequent trace variants: 0.311543\n",
            "Fitness value of 22-most frequent trace variants: 0.310897\n",
            "Fitness value of 23-most frequent trace variants: 0.306933\n",
            "Fitness value of 24-most frequent trace variants: 0.305758\n",
            "Fitness value of 25-most frequent trace variants: 0.302918\n",
            "Fitness value of 26-most frequent trace variants: 0.302212\n",
            "Fitness value of 27-most frequent trace variants: 0.303073\n",
            "Fitness value of 28-most frequent trace variants: 0.301238\n",
            "Fitness value of 29-most frequent trace variants: 0.299673\n",
            "Fitness value of 30-most frequent trace variants: 0.300833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zBMYE1_Dhzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}